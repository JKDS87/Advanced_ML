{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf79adf8-d2c1-4e15-8e4b-38cd7580e076",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2e38a-c1a3-4094-b6ab-dbecbe06e5f5",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "- Describe text vectorization\n",
    "- Vectorize text with sklearn\n",
    "- Compare count vectorization to TFIDF vectorization\n",
    "- Customize vectorization with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9540ad-60cb-42ff-a2a4-089381e572aa",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da65478-c0a7-446f-ad5a-e3bd68e39942",
   "metadata": {},
   "source": [
    "\n",
    "Machine learning models require numerical input and output, but text is inherently non-numerical. We need to transform our text data into a numerical format to ensure our data is in a format that machine learning algorithms can interpret. This process is known as text vectorization.\r\n",
    "\r\n",
    "Text vectorization is the process of converting text data into numeric data. There are various methods for achieving this, ranging from simple techniques like counting the occurrence of each word in each document (as done by CountVectorizer), to more complex methods like TF-IDF (Term Frequency-Inverse Document Frequency), which weighs the importance of terms based on their frequency in a document relative to their frequency in the entire corpus.\r\n",
    "\r\n",
    "Beyond traditional methods like CountVectorizer and TfidfVectorizer, there are also more advanced techniques like word embeddings. Word embeddings are dense vectors that capture semantic meanings of words based on their context, and they often provide more nuanced representations than methods based solely on term frequency. While this lesson will focus on CountVectorizer and TfidfVectorizer, it's important to know that word embeddings offer another powerful tool for text vectorization, which we will cover in the following week.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7d26a-dcb8-47e5-b456-2987a0f8d27c",
   "metadata": {},
   "source": [
    "**What is it?**\n",
    "\n",
    "Machine learning models require numerical input and output, but text is inherently non-numerical. We need to transform our text data into a numerical format to ensure our data is in a format that machine learning algorithms can interpret. This process is known as text vectorization.\n",
    "\n",
    "Text vectorization is the process of converting text data into numeric data. There are various methods for achieving this, ranging from simple techniques like counting the occurrence of each word in each document (as done by CountVectorizer), to more complex methods like TF-IDF (Term Frequency-Inverse Document Frequency), which weighs the importance of terms based on their frequency in a document relative to their frequency in the entire corpus.\n",
    "\n",
    "Beyond traditional methods like CountVectorizer and TfidfVectorizer, there are also more advanced techniques like word embeddings. Word embeddings are dense vectors that capture semantic meanings of words based on their context, and they often provide more nuanced representations than methods based solely on term frequency. While this lesson will focus on CountVectorizer and TfidfVectorizer, it's important to know that word embeddings offer another powerful tool for text vectorization, which we will cover in the following week.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a12bc4-98e9-4a3a-a544-262a0a37d6a4",
   "metadata": {},
   "source": [
    "### Imports, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0fb5023-90df-44fd-a8f1-aaa0545399ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d32af-95b2-4b57-bb42-db2e5eadf966",
   "metadata": {},
   "source": [
    "**Data**\n",
    "\n",
    "We will write 4 sentences to serve as our sample data. In this example, each sentence is considered a \"document,\" and the 4 sentences together are considered the \"corpus.\"TF_\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05151508-be51-49e9-898d-adce15cbe4df",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fac92-3322-4eaa-b94d-3de8934a0da8",
   "metadata": {},
   "source": [
    "Count vectorization is one of the simplest methods of converting text data into vectors. It tokenizes the text along with performing very basic preprocessing. The Count Vectorizer simply counts the occurrences of each unique word in each document and constructs a document-term matrix (DTM) from these counts.\n",
    "\n",
    "Conceptually:\n",
    "1. Tokenize the text: Break down the text into words (or n-grams, if specified).\n",
    "2. Build a vocabulary: Create a vocabulary of unique words from the entire corpus.\n",
    "3. Generate vectors: For each document, count the occurrences of each word in the vocabulary and store it in a vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e62e3ab-4e9d-4b60-a924-56bea7b1c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentences\n",
    "X = np.array([\n",
    "    \"I enjoy learning new programming languages. The best is Python. Programming is so fun!\",\n",
    "    \"I love programming, I would give it an A+!\",\n",
    "    \"Programming is amazing. Programming is love. Programming is life.\",\n",
    "    \"Python is my favorite programming language.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622602b-a5e7-46a7-9a87-2f5c08c5fa7f",
   "metadata": {},
   "source": [
    "We will start by instantiating a default version of the CountVectorizer. We will fit it on our sample data (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e825e880-9410-4691-89c8-b5d80f5bdb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# instantiate a vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# Fit it on the data \n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf7b5c-1a74-455c-b272-84f698ab4304",
   "metadata": {},
   "source": [
    "After fitting, we can find the full vocabulary the vectorizer used by checking the .vocabulary_ attribute. It will return a dictionary of unique vocabulary words as the keys and an integer assigned to the word as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e69e8e-04cc-449e-af1a-558a0b1b75e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saves vocab - matches number of columns above\n",
    "vocab_dict = vectorizer.vocabulary_\n",
    "type(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f7988b-6a8e-438b-b08b-5585af3576e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words in our vocab?\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd408af1-85c0-465d-98ff-95c928f3b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enjoy': 3,\n",
       " 'learning': 11,\n",
       " 'new': 15,\n",
       " 'programming': 16,\n",
       " 'languages': 10,\n",
       " 'the': 19,\n",
       " 'best': 2,\n",
       " 'is': 7,\n",
       " 'python': 17,\n",
       " 'so': 18,\n",
       " 'fun': 5,\n",
       " 'love': 13,\n",
       " 'would': 20,\n",
       " 'give': 6,\n",
       " 'it': 8,\n",
       " 'an': 1,\n",
       " 'amazing': 0,\n",
       " 'life': 12,\n",
       " 'my': 14,\n",
       " 'favorite': 4,\n",
       " 'language': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a small dictionary, so we can display it here.\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0babaab-1210-446b-9f7a-79142e1ceff0",
   "metadata": {},
   "source": [
    "Note that the integer in the dictionary is simply an identifier that has been assigned based on the alphabetical order of the word. \"Amazing\" is assigned integer \"0\" while \"would\" is assigned integer 20.\n",
    "\n",
    "We must transform the X data with the fitted vectorizer to obtain the count associated with each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8703c9de-8289-468a-b479-84c2b4a62eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To obtain the count, transform the X data\n",
    "X_count = vectorizer.transform(X)\n",
    "type(X_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc3dab-0685-43cb-a139-e065fa85b978",
   "metadata": {},
   "source": [
    "Vectorizers return sparse matrices to save memory. We can convert these to numpy arrays using the .toarray() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435c19e2-4822-4584-bd00-33a80a3b7594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sparse matrix to array for display\n",
    "X_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904313c6-cd13-4524-ad9c-3a91cb358515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the array\n",
    "X_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b774300-7154-435f-9502-855c40ab1551",
   "metadata": {},
   "source": [
    "There are four rows, each corresponding to one of the original sentences. There are 21 columns, each corresponding to a unique word used anywhere in the corpus.\n",
    "\n",
    "It is easier to interpret when displayed as a dataframe. We can name the columns using .get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a0e27f-c9ff-479f-a413-ce07d0220ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>give</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>my</th>\n",
       "      <th>new</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  an  best  enjoy  favorite  fun  give  is  it  language  ...  \\\n",
       "0        0   0     1      1         0    1     0   2   0         0  ...   \n",
       "1        0   1     0      0         0    0     1   0   1         0  ...   \n",
       "2        1   0     0      0         0    0     0   3   0         0  ...   \n",
       "3        0   0     0      0         1    0     0   1   0         1  ...   \n",
       "\n",
       "   learning  life  love  my  new  programming  python  so  the  would  \n",
       "0         1     0     0   0    1            2       1   1    1      0  \n",
       "1         0     0     1   0    0            1       0   0    0      1  \n",
       "2         0     1     1   0    0            3       0   0    0      0  \n",
       "3         0     0     0   1    0            1       1   0    0      0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make array into a df\n",
    "X_count_df = pd.DataFrame(X_count.toarray(), columns= vectorizer.get_feature_names_out())\n",
    "X_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b1316-992a-4348-9396-137132765092",
   "metadata": {},
   "source": [
    "Now, we can see the results of the Count Vectorizer. Let's examine the column for \"programming.\" We see that the term \"programming\" occurs twice in the first sentence (index 0), once in the sentence at index 1, three times in the sentence at index 2, and once in the sentence at index 3.\n",
    "\n",
    "We also find that using the default CountVectorizer resulted in:\n",
    "- The words have been converted to lowercase.\n",
    "- Words that were less than 2 letters long were removed.\n",
    "- Stopwords were NOT removed.\n",
    "- Punctuation WAS removed.\n",
    "\n",
    "We can control and customize the preprocessing performed by the CountVectorizer and have it perform more of our preprocessing simultaneously. Before we demonstrate the customization of the CountVectorrizer, we will introduce an alternative method of vectorization.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd3dbc-c3f2-40ef-9b90-f0a03901bc12",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ed8ac-2c86-459d-8146-acbe373e88fa",
   "metadata": {},
   "source": [
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, a statistic that reflects how important a word is to a document relative to a corpus. It considers the frequency of a word in a particular document and how unique the word is across all documents.\n",
    "\n",
    "- Term Frequency: This is simply the number of times a word appears in a document. (This is the same value given by the count vectorizer.)\n",
    "- Inverse Document Frequency\n",
    "    - n is total number of documents\n",
    "    - df is number of documents that contain the term, t\n",
    "    - The calculation (not yet linked) reduces the weight of terms that appear frequently across documents and increases the weight of terms that appear in fewer documents. (A higher weight is given to unique words.)\n",
    " \n",
    "By applying the TF-IDF formula, each term in each document in the corpus ends up with a TF-IDF weight that represents its importance in that document relative to the entire corpus. The TF-IDF weight (sometimes called TF-IDF score) will range from 0-1.\r\n",
    "\n",
    "\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a912f-6cf2-4974-a84c-ed64e7bcf361",
   "metadata": {},
   "source": [
    "### Using Sklearn's TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d87ed6-43cb-4ef1-a06e-414251cf35bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>give</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>my</th>\n",
       "      <th>new</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.3099</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5296</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing     an   best  enjoy  favorite    fun   give      is     it  \\\n",
       "0   0.0000  0.000  0.297  0.297    0.0000  0.297  0.000  0.3791  0.000   \n",
       "1   0.0000  0.452  0.000  0.000    0.0000  0.000  0.452  0.0000  0.452   \n",
       "2   0.3383  0.000  0.000  0.000    0.0000  0.000  0.000  0.6477  0.000   \n",
       "3   0.0000  0.000  0.000  0.000    0.4822  0.000  0.000  0.3078  0.000   \n",
       "\n",
       "   language  ...  learning    life    love      my    new  programming  \\\n",
       "0    0.0000  ...     0.297  0.0000  0.0000  0.0000  0.297       0.3099   \n",
       "1    0.0000  ...     0.000  0.0000  0.3564  0.0000  0.000       0.2359   \n",
       "2    0.0000  ...     0.000  0.3383  0.2667  0.0000  0.000       0.5296   \n",
       "3    0.4822  ...     0.000  0.0000  0.0000  0.4822  0.000       0.2516   \n",
       "\n",
       "   python     so    the  would  \n",
       "0  0.2341  0.297  0.297  0.000  \n",
       "1  0.0000  0.000  0.000  0.452  \n",
       "2  0.0000  0.000  0.000  0.000  \n",
       "3  0.3801  0.000  0.000  0.000  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# TfidfVectorizer Example\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns= tfidf_vectorizer.get_feature_names_out())\n",
    "X_tfidf_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc787652-3b19-4eb8-ae0f-0d77c4fe37e3",
   "metadata": {},
   "source": [
    "Notice that the value for each term is no longer a simple count. Again, looking at \"programming\" as an example, we can see that it now has values calculated based on the frequency of the term in the document and within the corpus. All TF-IDF scores are scaled to obtain values from 0-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799e959-4611-43a5-873c-dd6453d5d0cb",
   "metadata": {},
   "source": [
    "### Comparison: CountVectorizer vs TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec880bac-c481-4139-acf9-cb1d703c9266",
   "metadata": {},
   "source": [
    "![table](https://assets.codingdojo.com/boomyeah2015/codingdojo/curriculum/content/chapter/1698079860__Screenshot20231023125045.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10480e-e830-4774-928c-05307020b356",
   "metadata": {},
   "source": [
    "- CountVectorizer: Simple word counts. Common words that appear in many documents could overshadow meaningful terms.\n",
    "    - Use CountVectorizer when you want a simple representation and do not need to consider the importance of a term relative to the corpus.\r",
    "- TfidfVectorizer: Weights the word counts by a measure of how often they appear in the documents, which helps to adjust for the frequency of words across all documents.\n",
    "    - Use TfidfVectorizer when you want to determine important terms that are relevant in the context of the entire corpus.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0bd32-428e-485d-b4a1-2c9f43e71974",
   "metadata": {},
   "source": [
    "### Preprocessing using sklearn's vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62391c6b-b541-4b62-9f9d-46e0793e67d5",
   "metadata": {},
   "source": [
    "Either vectorizer can also perform additional preprocessing on the text data, such as:\n",
    "- Eliminating stopwords\n",
    "- Creating n-grams as well as single tokens\n",
    "- Changing tokenization patterns (or using a custom function to tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da76c40-a9d0-41a4-8d18-2ee9fb400131",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11cec13-a8a7-465d-b11f-db44641d2df2",
   "metadata": {},
   "source": [
    "The CountVectorizer has a stop_words parameter that can be one of the following:\n",
    "- None (default): no stopwords removed\n",
    "- 'english' (keyword): removes the list of stopwords from `sklearn.feature_extraction.text.ENGLISH_STOP_WORDS`\n",
    "\n",
    "\n",
    "Here, we use stop_words arg when instantiating CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8512f3c3-87a8-4523-b7bb-fce1ab919c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>new</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  best  enjoy  favorite  fun  language  languages  learning  life  \\\n",
       "0        0     1      1         0    1         0          1         1     0   \n",
       "1        0     0      0         0    0         0          0         0     0   \n",
       "2        1     0      0         0    0         0          0         0     1   \n",
       "3        0     0      0         1    0         1          0         0     0   \n",
       "\n",
       "   love  new  programming  python  \n",
       "0     0    1            2       1  \n",
       "1     1    0            1       0  \n",
       "2     1    0            3       0  \n",
       "3     0    0            1       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer\n",
    "vectorizer_stopped = CountVectorizer(stop_words='english')\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_stopped.fit_transform(X)\n",
    "X_stopped = pd.DataFrame(X_vec.toarray(), columns= vectorizer_stopped.get_feature_names_out())\n",
    "X_stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8a9f0-7838-4961-9d04-f8407bd4454b",
   "metadata": {},
   "source": [
    "We have reduced the number of words by eliminating stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd07639-c75d-478d-a832-b907184d450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of terms in original vocabulary: 21\n",
      "# of terms in stopwords-removed vocabulary: 13\n"
     ]
    }
   ],
   "source": [
    "# Comparing default vocab \n",
    "print(f\"# of terms in original vocabulary: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"# of terms in stopwords-removed vocabulary: {len(vectorizer_stopped.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8096c-ad4a-4415-97ec-db03d0eebc78",
   "metadata": {},
   "source": [
    "Some of the stopwords that were removed include \"an,\" \"is,\" and \"it.\"\n",
    "\n",
    "Note that we can perform the same customization with the TFIDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48985e2-9552-46d0-990e-15b2e25e5d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>new</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360121</td>\n",
       "      <td>0.375852</td>\n",
       "      <td>0.283924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551939</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444008</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.695105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306758</td>\n",
       "      <td>0.463458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazing      best     enjoy  favorite       fun  language  languages  \\\n",
       "0  0.000000  0.360121  0.360121  0.000000  0.360121  0.000000   0.360121   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "2  0.444008  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.587838  0.000000  0.587838   0.000000   \n",
       "\n",
       "   learning      life      love       new  programming    python  \n",
       "0  0.360121  0.000000  0.000000  0.360121     0.375852  0.283924  \n",
       "1  0.000000  0.000000  0.833884  0.000000     0.551939  0.000000  \n",
       "2  0.000000  0.444008  0.350061  0.000000     0.695105  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000     0.306758  0.463458  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer\n",
    "vectorizer_tfidf_stopped = TfidfVectorizer(stop_words='english')\n",
    "# Fit it on the data \n",
    "X_vec_tfidf_stopped = vectorizer_tfidf_stopped.fit_transform(X)\n",
    "X_stopped_tfidf = pd.DataFrame(X_vec_tfidf_stopped.toarray(), columns= vectorizer_tfidf_stopped.get_feature_names_out())\n",
    "X_stopped_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef7124-a84b-49a0-9b09-725e7069617a",
   "metadata": {},
   "source": [
    "Notice that we now have tfidf scores for only the \"non-stopwords.\"\n",
    "\n",
    "**Customized stopwords**\n",
    "\n",
    "We can also customize the list of stopwords as we have done in previous lessons. For example, we will include \"programming\" to the list of English stop words.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c75a2392-a12a-41ef-9f1f-d8095918ee0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>new</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  best  enjoy  favorite  fun  language  languages  learning  life  \\\n",
       "0        0     1      1         0    1         0          1         1     0   \n",
       "1        0     0      0         0    0         0          0         0     0   \n",
       "2        1     0      0         0    0         0          0         0     1   \n",
       "3        0     0      0         1    0         1          0         0     0   \n",
       "\n",
       "   love  new  python  \n",
       "0     0    1       1  \n",
       "1     1    0       0  \n",
       "2     1    0       0  \n",
       "3     0    0       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "custom_stopwords = [*ENGLISH_STOP_WORDS, 'programming']\n",
    "# instantiate a vectorizer\n",
    "vectorizer_stopped_custom = CountVectorizer(stop_words=custom_stopwords)\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_stopped_custom.fit_transform(X)\n",
    "X_stopped_custom = pd.DataFrame(X_vec.toarray(), columns= vectorizer_stopped_custom.get_feature_names_out())\n",
    "X_stopped_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e2851-5a9f-477f-8af6-8e0a3eb5acc0",
   "metadata": {},
   "source": [
    "### Changing Tokenization Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a696e-dc7c-4903-b761-7b1f73ade12d",
   "metadata": {},
   "source": [
    "The sklearn tokenizer uses its built-in tokenizer by default, but we can control the tokenization method by using the tokenizer argument when we instantiate the vectorizer.\r\n",
    "\r\n",
    "For example, we could use nltk's wordpunt_tokenizer, which will keep punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c41b5cf4-c5cd-453f-8995-5d735391383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>+!</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>new</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   !  +!  ,  .  amazing  best  enjoy  favorite  fun  language  languages  \\\n",
       "0  1   0  0  2        0     1      1         0    1         0          1   \n",
       "1  0   1  1  0        0     0      0         0    0         0          0   \n",
       "2  0   0  0  3        1     0      0         0    0         0          0   \n",
       "3  0   0  0  1        0     0      0         1    0         1          0   \n",
       "\n",
       "   learning  life  love  new  programming  python  \n",
       "0         1     0     0    1            2       1  \n",
       "1         0     0     1    0            1       0  \n",
       "2         0     1     1    0            3       0  \n",
       "3         0     0     0    0            1       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "# instantiate a vectorizer with english stopwords\n",
    "vectorizer_nltk = CountVectorizer(stop_words='english',\n",
    "                                  tokenizer=wordpunct_tokenize, token_pattern = None)\n",
    "# Fit it on the data \n",
    "X_count_nltk = vectorizer_nltk.fit_transform(X)\n",
    "# Getting the feature names (vocabulary)\n",
    "X_count_nltk_df = pd.DataFrame(X_count_nltk.toarray(), columns= vectorizer_nltk.get_feature_names_out())\n",
    "X_count_nltk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56c916-0105-495c-af7e-a9bce6ad704c",
   "metadata": {},
   "source": [
    "We can customize the tokenizer used with tfidf vectorizor using the same syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38d0bb6f-3cb9-4d5e-b72c-f1b5ed770754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>+!</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>new</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.324562</td>\n",
       "      <td>0.245178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647743</td>\n",
       "      <td>0.338271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338271</td>\n",
       "      <td>0.266697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529572</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287207</td>\n",
       "      <td>0.433919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          !        +!         ,         .   amazing      best     enjoy  \\\n",
       "0  0.310978  0.000000  0.000000  0.396986  0.000000  0.310978  0.310978   \n",
       "1  0.000000  0.587838  0.587838  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.647743  0.338271  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.351295  0.000000  0.000000  0.000000   \n",
       "\n",
       "   favorite       fun  language  languages  learning      life      love  \\\n",
       "0  0.000000  0.310978  0.000000   0.310978  0.310978  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.463458   \n",
       "2  0.000000  0.000000  0.000000   0.000000  0.000000  0.338271  0.266697   \n",
       "3  0.550372  0.000000  0.550372   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        new  programming    python  \n",
       "0  0.310978     0.324562  0.245178  \n",
       "1  0.000000     0.306758  0.000000  \n",
       "2  0.000000     0.529572  0.000000  \n",
       "3  0.000000     0.287207  0.433919  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "# instantiate a vectorizer with english stopwords\n",
    "vectorizer_nltk = TfidfVectorizer(stop_words='english',\n",
    "                                  tokenizer=wordpunct_tokenize, token_pattern = None)\n",
    "# Fit it on the data \n",
    "X_count_nltk = vectorizer_nltk.fit_transform(X)\n",
    "# Getting the feature names (vocabulary)\n",
    "X_count_nltk_df = pd.DataFrame(X_count_nltk.toarray(), columns= vectorizer_nltk.get_feature_names_out())\n",
    "X_count_nltk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ae943-ee93-423e-bb0c-360cc4d605a6",
   "metadata": {},
   "source": [
    "### Ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a6a6b-69ad-4eea-acd7-71650b4c130d",
   "metadata": {},
   "source": [
    "The vectorizers also have the option to extract not just single tokens but n-grams as well.\r\n",
    "\r\n",
    "We specify this using the ngram_range argument, which is a tuple of the min and max number of words included in a token.\r\n",
    "\r\n",
    "The default is ngram_range=(1,1) which indicates that only single words will be tokenized. If we specify ngram_range=(1,2), it will find bigrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48466aa9-b75a-44e6-8869-6c97fd7ef70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>amazing programming</th>\n",
       "      <th>best</th>\n",
       "      <th>best python</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>enjoy learning</th>\n",
       "      <th>favorite</th>\n",
       "      <th>favorite programming</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>programming</th>\n",
       "      <th>programming amazing</th>\n",
       "      <th>programming fun</th>\n",
       "      <th>programming language</th>\n",
       "      <th>programming languages</th>\n",
       "      <th>programming life</th>\n",
       "      <th>programming love</th>\n",
       "      <th>python</th>\n",
       "      <th>python favorite</th>\n",
       "      <th>python programming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  amazing programming  best  best python  enjoy  enjoy learning  \\\n",
       "0        0                    0     1            1      1               1   \n",
       "1        0                    0     0            0      0               0   \n",
       "2        1                    1     0            0      0               0   \n",
       "3        0                    0     0            0      0               0   \n",
       "\n",
       "   favorite  favorite programming  fun  language  ...  programming  \\\n",
       "0         0                     0    1         0  ...            2   \n",
       "1         0                     0    0         0  ...            1   \n",
       "2         0                     0    0         0  ...            3   \n",
       "3         1                     1    0         1  ...            1   \n",
       "\n",
       "   programming amazing  programming fun  programming language  \\\n",
       "0                    0                1                     0   \n",
       "1                    0                0                     0   \n",
       "2                    1                0                     0   \n",
       "3                    0                0                     1   \n",
       "\n",
       "   programming languages  programming life  programming love  python  \\\n",
       "0                      1                 0                 0       1   \n",
       "1                      0                 0                 0       0   \n",
       "2                      0                 1                 1       0   \n",
       "3                      0                 0                 0       1   \n",
       "\n",
       "   python favorite  python programming  \n",
       "0                0                   1  \n",
       "1                0                   0  \n",
       "2                0                   0  \n",
       "3                1                   0  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer to include bigrams\n",
    "vectorizer_ngrams = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_ngrams.fit_transform(X)\n",
    "X_ngrams = pd.DataFrame(X_vec.toarray(), columns= vectorizer_ngrams.get_feature_names_out())\n",
    "X_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b1f2d-ff37-459f-9ec6-3108766ce968",
   "metadata": {},
   "source": [
    "Notice that we have single words and bigrams.\n",
    "\n",
    "We could include trigrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c435caf-0ea5-4608-a834-a41e4cf7646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>amazing programming</th>\n",
       "      <th>amazing programming love</th>\n",
       "      <th>best</th>\n",
       "      <th>best python</th>\n",
       "      <th>best python programming</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>enjoy learning</th>\n",
       "      <th>enjoy learning new</th>\n",
       "      <th>favorite</th>\n",
       "      <th>...</th>\n",
       "      <th>programming languages</th>\n",
       "      <th>programming languages best</th>\n",
       "      <th>programming life</th>\n",
       "      <th>programming love</th>\n",
       "      <th>programming love programming</th>\n",
       "      <th>python</th>\n",
       "      <th>python favorite</th>\n",
       "      <th>python favorite programming</th>\n",
       "      <th>python programming</th>\n",
       "      <th>python programming fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  amazing programming  amazing programming love  best  best python  \\\n",
       "0        0                    0                         0     1            1   \n",
       "1        0                    0                         0     0            0   \n",
       "2        1                    1                         1     0            0   \n",
       "3        0                    0                         0     0            0   \n",
       "\n",
       "   best python programming  enjoy  enjoy learning  enjoy learning new  \\\n",
       "0                        1      1               1                   1   \n",
       "1                        0      0               0                   0   \n",
       "2                        0      0               0                   0   \n",
       "3                        0      0               0                   0   \n",
       "\n",
       "   favorite  ...  programming languages  programming languages best  \\\n",
       "0         0  ...                      1                           1   \n",
       "1         0  ...                      0                           0   \n",
       "2         0  ...                      0                           0   \n",
       "3         1  ...                      0                           0   \n",
       "\n",
       "   programming life  programming love  programming love programming  python  \\\n",
       "0                 0                 0                             0       1   \n",
       "1                 0                 0                             0       0   \n",
       "2                 1                 1                             1       0   \n",
       "3                 0                 0                             0       1   \n",
       "\n",
       "   python favorite  python favorite programming  python programming  \\\n",
       "0                0                            0                   1   \n",
       "1                0                            0                   0   \n",
       "2                0                            0                   0   \n",
       "3                1                            1                   0   \n",
       "\n",
       "   python programming fun  \n",
       "0                       1  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "\n",
       "[4 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer to include bigrams and trigrams\n",
    "vectorizer_ngrams = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_ngrams.fit_transform(X)\n",
    "X_ngrams = pd.DataFrame(X_vec.toarray(), columns= vectorizer_ngrams.get_feature_names_out())\n",
    "X_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bebffa9d-c294-4836-a5fd-a07a44960316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer_ngrams.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278dc081-934a-4416-bbcd-d945c51a1c41",
   "metadata": {},
   "source": [
    "Be cautious about using n-grams larger than 2 to avoid running out of RAM. Note that the number of terms dramatically increases as n increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7273cc-2f9a-4f6e-80e1-9869ca7bb4d6",
   "metadata": {},
   "source": [
    "### Manually Controlling Vocabulary Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b381a-6110-4122-a144-07b0818ae5fd",
   "metadata": {},
   "source": [
    "Once we start using a full dataset, we may have thousands or hundreds of thousands of terms in our vocabulary.\n",
    "\n",
    "We can artificially reduce the number of words included by changing the max_features argument. The vectorizer will only keep the top max_features # of the most common words in the final text data.\n",
    "\n",
    "While this may improve the speed of our models, it may also lose much of the document's original meaning, especially if we limit the number of features and do not remove stopwords. (they are so common they would out-compete the more meaningful terms in the corpus).\n",
    "\n",
    "**max_features**\n",
    "\n",
    "We can limit the size of our vectorized data by reducing the maximum number of words included in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "227e8eb3-591b-4f67-a3b1-fd47d8add550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>love</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  best  enjoy  favorite  fun  language  languages  love  \\\n",
       "0        0     1      1         0    1         0          1     0   \n",
       "1        0     0      0         0    0         0          0     1   \n",
       "2        1     0      0         0    0         0          0     1   \n",
       "3        0     0      0         1    0         1          0     0   \n",
       "\n",
       "   programming  python  \n",
       "0            2       1  \n",
       "1            1       0  \n",
       "2            3       0  \n",
       "3            1       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer\n",
    "vectorizer_max10 = CountVectorizer(stop_words='english', max_features=10)\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_max10.fit_transform(X)\n",
    "X_max10 = pd.DataFrame(X_vec.toarray(), columns= vectorizer_max10.get_feature_names_out())\n",
    "X_max10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b978c82-1570-42ce-ac28-8650c03e2368",
   "metadata": {},
   "source": [
    "**max_df (maximum document frequency)**\n",
    "\n",
    "Any terms that appear in more than max_df proportion of documents will be ignored. Here we will set the max_df to 0.5. This will eliminate any words that occur in more than half of the documents. If an integer is used, it will define the maximum number of documents the term can appear in.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb94c20b-bd90-471a-b97c-3d766f5d6393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>favorite</th>\n",
       "      <th>fun</th>\n",
       "      <th>language</th>\n",
       "      <th>languages</th>\n",
       "      <th>learning</th>\n",
       "      <th>life</th>\n",
       "      <th>love</th>\n",
       "      <th>new</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  best  enjoy  favorite  fun  language  languages  learning  life  \\\n",
       "0        0     1      1         0    1         0          1         1     0   \n",
       "1        0     0      0         0    0         0          0         0     0   \n",
       "2        1     0      0         0    0         0          0         0     1   \n",
       "3        0     0      0         1    0         1          0         0     0   \n",
       "\n",
       "   love  new  python  \n",
       "0     0    1       1  \n",
       "1     1    0       0  \n",
       "2     1    0       0  \n",
       "3     0    0       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer\n",
    "vectorizer_maxdf = CountVectorizer(stop_words='english', max_df = .5)\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_maxdf.fit_transform(X)\n",
    "X_maxdf = pd.DataFrame(X_vec.toarray(), columns= vectorizer_maxdf.get_feature_names_out())\n",
    "X_maxdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dabd6e-5593-4aa1-9bea-ee3ddd29a74c",
   "metadata": {},
   "source": [
    "Notice, that \"programming\" does not appear because it is in more than 50% of the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4ae9f-8f05-437c-a50b-93f595b7eac7",
   "metadata": {},
   "source": [
    "**min_df (minimum document frequency)**\n",
    "\n",
    "Any terms that appear in less than min_df proportion of documents will be ignored. If an integer is used, it will define the minimum number of documents the term must appear in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "111e5051-ca77-42d2-b83a-5db9432c5588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>love</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   love  programming  python\n",
       "0     0            2       1\n",
       "1     1            1       0\n",
       "2     1            3       0\n",
       "3     0            1       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a vectorizer\n",
    "vectorizer_mindf = CountVectorizer(stop_words='english', min_df = .5)\n",
    "# Fit it on the data \n",
    "X_vec = vectorizer_mindf.fit_transform(X)\n",
    "X_mindf = pd.DataFrame(X_vec.toarray(), columns= vectorizer_mindf.get_feature_names_out())\n",
    "X_mindf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29bf735-1bd9-49b4-a4cc-f7b60c7fa956",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae2ce1-fbae-4c02-a5f4-194a09e67a66",
   "metadata": {},
   "source": [
    "In this lesson, you've learned about two popular methods for text vectorization: CountVectorizer and TfidfVectorizer. CountVectorizer is simple and effective for transforming text into numerical vectors based on word frequency. TfidfVectorizer offers a more sophisticated method that considers the importance of each term relative to the entire corpus. Sklearn's vectorizers can be customized using similar syntax. Both are powerful tools in the field of text analytics and are essential for further tasks like text classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
