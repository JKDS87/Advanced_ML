{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46178f5d-09b4-47a3-beb4-5f733d676bf2",
   "metadata": {},
   "source": [
    "# Creating a File Structure for Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a64a7b-1e25-4a7e-bf92-dce454bd08d0",
   "metadata": {},
   "source": [
    "In developing Streamlit applications, managing the files and paths to datasets and model artifacts is crucial for clean and maintainable code. Using JSON (JavaScript Object Notation) to store and track these file paths offers a structured, readable, and flexible approach to handling these resources. In this lesson, we'll explore using a JSON configuration file to manage paths within a Streamlit app effectively.\n",
    "\n",
    "A streamlit dashboard can have many aspects/components, all with their own assets. It can take time to run the modeling code live, leaving the user waiting, so we pre-save as many of the components and variables we will need as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ff53b-6722-4812-a07a-0b11cf90afbc",
   "metadata": {},
   "source": [
    "Some of the files we may want to track are:\n",
    "\n",
    "\n",
    "- data:\n",
    "    - Full dataframe of dataset used\n",
    "    - EDA/preview DataFrame\n",
    "    - Data from Machine Learning (ML) Models (if applicable):\n",
    "        - train-data.joblib (X_train, y_train)\n",
    "        - test-data.joblib (X_test, y_test)\n",
    "    - Data from Neural Network (NN) Models (if applicable):\n",
    "        - TF records (saving Tensorflow Datasets)\n",
    "- models:\n",
    "    - for Machine Learning (ML): joblib file or tensorflow model folder)\n",
    "    - for Neural Networks (NN): saved keras model folder.\n",
    "- images:\n",
    "    - App assets (e.g. banner png image)\n",
    "    - Saved Figures\n",
    "- config:\n",
    "    - a file for tracking all of the filepaths above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fd1de1-52c1-488c-bd15-67297bff5e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'ml': {'test': 'data/testing-data.joblib',\n",
      "                 'train': 'data/training-data.joblib'},\n",
      "          'raw': {'eda': 'data/ames-housing-dojo-for-ml-eda.csv',\n",
      "                  'full': 'data/ames-housing-dojo-for-ml.csv'}},\n",
      " 'images': {'banner': 'images/app-banner.png'},\n",
      " 'models': {'linear_regression': 'models/linear_regression/linreg.joblib',\n",
      "            'random_forest': 'models/random_forest/rf_reg.joblib'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "FPATHS = dict(\n",
    "    data={\n",
    "        \"raw\": {\n",
    "            \"full\": \"data/ames-housing-dojo-for-ml.csv\",  # (This is the original full dataframe we already have)\n",
    "            \"eda\": \"data/ames-housing-dojo-for-ml-eda.csv\" # We haven't saved this yet\n",
    "        },\n",
    "        \"ml\": {\n",
    "            \"train\": \"data/training-data.joblib\",  # (X_train,y_train) We haven't saved this yet\n",
    "            \"test\": \"data/testing-data.joblib\",  # (X_test,y_test) We haven't saved this yet\n",
    "        },\n",
    "    },\n",
    "    models={\n",
    "        \"linear_regression\": \"models/linear_regression/linreg.joblib\", # We haven't saved this yet\n",
    "        \"random_forest\": \"models/random_forest/rf_reg.joblib\", # We haven't saved this yet\n",
    "    },\n",
    "    images={\n",
    "        \"banner\": \"images/app-banner.png\", # We haven't saved this yet\n",
    "    },\n",
    ")\n",
    "pprint(FPATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc1f67-29c7-4c1e-9218-783db7bdd42b",
   "metadata": {},
   "source": [
    "We can then save the dictionary to a file immediately since we will use the file paths within it to name the files we will save. There are several places/ways you could do this, but we will demonstrate creating a \"config/\" folder, which will contain our dictionary of file paths as \"config/filepaths.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65885f99-6d9e-4550-bacf-2f14f9ab6662",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Save the filepaths \n",
    "import os, json\n",
    "os.makedirs('config/', exist_ok=True)\n",
    "FPATHS_FILE = 'config/filepaths.json'\n",
    "with open(FPATHS_FILE, 'w') as f:\n",
    "    json.dump(FPATHS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8a493-3341-451d-80f0-05c9c05fddc7",
   "metadata": {},
   "source": [
    "Now that we have defined our file paths, we can optionally look through our FPATHS dictionary, find the directory name (folder name) in the file path, and then use the os module to create the directories. This will avoid issues saving files later if the folder hasn't been created yet. Below, we have a function to accomplish this with our nested dictionary.\n",
    "\n",
    "The function below will create all of the directories (folders) specified in our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8bb067-64ab-4d78-8754-b232b105f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: models/linear_regression\n",
      "Directory created: models/random_forest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def create_directories_from_paths(nested_dict):\n",
    "    \"\"\"OpenAI. (2023). ChatGPT [Large language model]. https://chat.openai.com \n",
    "    Recursively create directories for file paths in a nested dictionary.\n",
    "    Parameters:\n",
    "    nested_dict (dict): The nested dictionary containing file paths.\n",
    "    \"\"\"\n",
    "    for key, value in nested_dict.items():\n",
    "        if isinstance(value, dict):\n",
    "            # If the value is a dictionary, recurse into it\n",
    "            create_directories_from_paths(value)\n",
    "        elif isinstance(value, str):\n",
    "            # If the value is a string, treat it as a file path and get the directory path\n",
    "            directory_path = os.path.dirname(value)\n",
    "            # If the directory path is not empty and the directory does not exist, create it\n",
    "            if directory_path and not os.path.exists(directory_path):\n",
    "                os.makedirs(directory_path)\n",
    "                print(f\"Directory created: {directory_path}\")\n",
    "\n",
    "# Use the function on your FPATHS dictionary\n",
    "create_directories_from_paths(FPATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8acaea6-c90b-4965-9c68-7abb6c2129e0",
   "metadata": {},
   "source": [
    "If you return to your Jupyter Home tab, you will see new folders have been created. For example, there is a \"models\" folder containing two folders: \"linear_regression\" and \"random_forest\".\n",
    "\n",
    "We can access a file name using our dictionary. The example below accesses a file name for a file that exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0b7a57-958e-4e52-ac01-711e9ebe3df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ames-housing-dojo-for-ml.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access a file using our dictionary\n",
    "FPATHS['data']['raw']['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e89f18-d7a5-4959-b4d9-52466a5deb2e",
   "metadata": {},
   "source": [
    "The example below accesses a file name for a file we have not yet created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8a5ec8-a827-4d95-b2ea-47db511f2b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/random_forest/rf_reg.joblib'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access a file using our dictionary\n",
    "FPATHS['models']['random_forest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c8751-0ccd-42bc-b541-9ce0884a08f3",
   "metadata": {},
   "source": [
    "Now that we have created our file structure, we must create the rest of the files we will need for our app.\n",
    "\n",
    "**Banner Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d84d8de-7ab2-443b-94c8-754b150f7f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<img src='images/app-banner.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the images is in the correct location\n",
    "from IPython.display import display, Markdown\n",
    "Markdown(f\"<img src='{FPATHS['images']['banner']}'>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76819867-d52e-4cef-b148-92b732230692",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c50873-6762-4d62-ad73-382a99a6a681",
   "metadata": {},
   "source": [
    "In this lesson, we defined a dictionary to organize the files we will use in our deployment app. We plan to use data, model, and image files for our app, so we have used those as our top-level keys. We created all of the folders we will need from our file structure dictionary. Next, we will make the rest of the required files and use our convenient dictionary to save them according to our file structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
